<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Mini AI XOR Demo</title>
  <style>
    body {
      background: #222;
      color: #fff;
      font-family: sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 100vh;
      margin: 0;
    }
    h1 {
      margin-bottom: 20px;
      text-align: center;
    }
    #log {
      width: 80%;
      max-width: 600px;
      background: #333;
      padding: 20px;
      border-radius: 8px;
      overflow-y: auto;
      max-height: 300px;
      font-family: monospace;
    }
  </style>
</head>
<body>
  <h1>Mini AI: XOR Neural Network</h1>
  <div id="log"></div>

  <script>
    /************************************************************
     * 1. Simple Utility Functions
     ************************************************************/
    // Activation function: Sigmoid
    function sigmoid(x) {
      return 1 / (1 + Math.exp(-x));
    }
    // Derivative of sigmoid
    function dsigmoid(y) {
      return y * (1 - y);
    }

    // Log to the on-page #log div
    function logMessage(msg) {
      const logDiv = document.getElementById('log');
      logDiv.textContent += msg + "\n";
    }

    /************************************************************
     * 2. Define a small 2-layer neural network
     ************************************************************/
    class NeuralNetwork {
      constructor(inputNodes, hiddenNodes, outputNodes, learningRate = 0.1) {
        this.inputNodes = inputNodes;
        this.hiddenNodes = hiddenNodes;
        this.outputNodes = outputNodes;
        this.learningRate = learningRate;

        // Initialize weights with random values
        // wIH: Weights from Input to Hidden
        this.wIH = Array.from({ length: this.hiddenNodes }, () =>
          Array.from({ length: this.inputNodes }, () => Math.random() * 2 - 1)
        );
        // wHO: Weights from Hidden to Output
        this.wHO = Array.from({ length: this.outputNodes }, () =>
          Array.from({ length: this.hiddenNodes }, () => Math.random() * 2 - 1)
        );

        // Initialize biases
        // bH: Bias for Hidden
        this.bH = Array.from({ length: this.hiddenNodes }, () => Math.random() * 2 - 1);
        // bO: Bias for Output
        this.bO = Array.from({ length: this.outputNodes }, () => Math.random() * 2 - 1);
      }

      // Forward pass
      predict(inputs) {
        // Hidden layer
        const hidden = this.wIH.map((row, i) => {
          // Weighted sum
          let sum = row.reduce((acc, w, j) => acc + w * inputs[j], 0);
          sum += this.bH[i]; // add bias
          // Activation
          return sigmoid(sum);
        });

        // Output layer
        const outputs = this.wHO.map((row, i) => {
          let sum = row.reduce((acc, w, j) => acc + w * hidden[j], 0);
          sum += this.bO[i]; // add bias
          return sigmoid(sum);
        });

        return outputs;
      }

      // Train with one data point
      train(inputs, targets) {
        // ----- Forward Pass -----
        // 1. Hidden
        const hidden = this.wIH.map((row, i) => {
          let sum = row.reduce((acc, w, j) => acc + w * inputs[j], 0);
          sum += this.bH[i];
          return sigmoid(sum);
        });
        // 2. Output
        const outputs = this.wHO.map((row, i) => {
          let sum = row.reduce((acc, w, j) => acc + w * hidden[j], 0);
          sum += this.bO[i];
          return sigmoid(sum);
        });

        // ----- Backward Pass (Calculate Errors) -----
        // Output errors (target - actual)
        const outputErrors = outputs.map((o, i) => targets[i] - o);

        // Hidden -> Output weight update
        // Î”w = learningRate * error * dSigmoid(output) * hiddenNeuron
        for (let i = 0; i < this.outputNodes; i++) {
          const error = outputErrors[i];
          const gradient = dsigmoid(outputs[i]) * error * this.learningRate;
          // Update bias for output layer
          this.bO[i] += gradient;
          // Update each weight in wHO
          for (let j = 0; j < this.hiddenNodes; j++) {
            const delta = gradient * hidden[j];
            this.wHO[i][j] += delta;
          }
        }

        // Calculate hidden layer errors
        // hiddenError = sum( wHO[i][h] * outputErrors[i] )
        const hiddenErrors = this.wIH.map(() => 0);
        for (let i = 0; i < this.outputNodes; i++) {
          for (let h = 0; h < this.hiddenNodes; h++) {
            hiddenErrors[h] += this.wHO[i][h] * outputErrors[i];
          }
        }

        // Input -> Hidden weight update
        for (let h = 0; h < this.hiddenNodes; h++) {
          const error = hiddenErrors[h];
          const gradient = dsigmoid(hidden[h]) * error * this.learningRate;
          // Update bias for hidden layer
          this.bH[h] += gradient;
          // Update each weight in wIH
          for (let inp = 0; inp < this.inputNodes; inp++) {
            const delta = gradient * inputs[inp];
            this.wIH[h][inp] += delta;
          }
        }
      }
    }

    /************************************************************
     * 3. Train the network on XOR data
     ************************************************************/
    const nn = new NeuralNetwork(2, 2, 1, 0.2);

    // XOR dataset
    const trainingData = [
      { inputs: [0, 0], targets: [0] },
      { inputs: [0, 1], targets: [1] },
      { inputs: [1, 0], targets: [1] },
      { inputs: [1, 1], targets: [0] }
    ];

    // We'll do a few thousand epochs for a stable learning
    const epochs = 4000;

    for (let i = 0; i < epochs; i++) {
      // Shuffle training data each epoch
      trainingData.sort(() => Math.random() - 0.5);
      // Train on each example
      for (let data of trainingData) {
        nn.train(data.inputs, data.targets);
      }
    }

    logMessage("Training complete after " + epochs + " epochs!");
    logMessage("Let's test the network on the XOR inputs:");

    // Test it
    trainingData.forEach(td => {
      const prediction = nn.predict(td.inputs);
      logMessage(
        `Input: ${td.inputs} -> Output: ${prediction[0].toFixed(3)} (Target: ${td.targets[0]})`
      );
    });
  </script>
</body>
</html>
